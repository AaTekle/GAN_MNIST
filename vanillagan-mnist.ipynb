{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets, transforms\nfrom torchvision.utils import make_grid, save_image\nimport os\nimport matplotlib.pyplot as plt\n\n# Check for GPU\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# Create directory for saving images\noutput_dir = \"/kaggle/working/generated_images\"\nos.makedirs(output_dir, exist_ok=True)\n\n# Hyperparameters\nlatent_dim = 100       # Dimension of noise vector\nimg_shape = (1, 28, 28)  # Shape of MNIST images\nbatch_size = 64\nlr = 0.0002\nepochs = 50\n\n# Transform to normalize data\ntransform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize([0.5], [0.5])  # Normalize images to [-1, 1]\n])\n\n# Load the MNIST dataset\ntrain_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\ndataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n# Define the Generator model\nclass Generator(nn.Module):\n    def __init__(self):\n        super(Generator, self).__init__()\n        self.model = nn.Sequential(\n            nn.Linear(latent_dim, 128),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Linear(128, 256),\n            nn.BatchNorm1d(256),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Linear(256, 512),\n            nn.BatchNorm1d(512),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Linear(512, int(torch.prod(torch.tensor(img_shape)))),\n            nn.Tanh()\n        )\n\n    def forward(self, z):\n        img = self.model(z)\n        img = img.view(img.size(0), *img_shape)\n        return img\n\n# Define the Discriminator model\nclass Discriminator(nn.Module):\n    def __init__(self):\n        super(Discriminator, self).__init__()\n        self.model = nn.Sequential(\n            nn.Linear(int(torch.prod(torch.tensor(img_shape))), 512),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Linear(512, 256),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Linear(256, 1),\n            nn.Sigmoid()\n        )\n\n    def forward(self, img):\n        img_flat = img.view(img.size(0), -1)\n        validity = self.model(img_flat)\n        return validity\n\n# Initialize models and move them to GPU if available\ngenerator = Generator().to(device)\ndiscriminator = Discriminator().to(device)\n\n# Loss and optimizer\nadversarial_loss = nn.BCELoss().to(device)\noptimizer_G = optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\noptimizer_D = optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))\n\n# Function to generate noise on the same device\ndef generate_noise(batch_size, latent_dim):\n    return torch.randn(batch_size, latent_dim, device=device)\n\n# Training loop\nfor epoch in range(epochs):\n    for i, (imgs, _) in enumerate(dataloader):\n        # Move images to device\n        imgs = imgs.to(device)\n\n        # Prepare labels\n        real_labels = torch.ones(imgs.size(0), 1, device=device)\n        fake_labels = torch.zeros(imgs.size(0), 1, device=device)\n\n        # Train Generator\n        optimizer_G.zero_grad()\n        z = generate_noise(imgs.size(0), latent_dim)\n        generated_imgs = generator(z)\n        g_loss = adversarial_loss(discriminator(generated_imgs), real_labels)\n        g_loss.backward()\n        optimizer_G.step()\n\n        # Train Discriminator\n        optimizer_D.zero_grad()\n        real_loss = adversarial_loss(discriminator(imgs), real_labels)\n        fake_loss = adversarial_loss(discriminator(generated_imgs.detach()), fake_labels)\n        d_loss = (real_loss + fake_loss) / 2\n        d_loss.backward()\n        optimizer_D.step()\n\n    # Log progress\n    print(f\"Epoch [{epoch+1}/{epochs}] - Loss D: {d_loss.item():.4f}, Loss G: {g_loss.item():.4f}\")\n\n    # Save generated images every 10 epochs\n    if epoch % 10 == 0:\n        with torch.no_grad():\n            test_noise = generate_noise(16, latent_dim)\n            test_imgs = generator(test_noise)\n            grid = make_grid(test_imgs, nrow=4, normalize=True)\n            save_image(grid, f\"generated_images/epoch_{epoch}.png\")\n            print(f\"Generated images saved at epoch {epoch}\")\n\nprint(\"Training complete.\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-05T14:51:46.642581Z","iopub.execute_input":"2024-11-05T14:51:46.643382Z","iopub.status.idle":"2024-11-05T15:05:27.873830Z","shell.execute_reply.started":"2024-11-05T14:51:46.643337Z","shell.execute_reply":"2024-11-05T15:05:27.872863Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\nDownloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\nFailed to download (trying next):\n<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 9912422/9912422 [00:00<00:00, 14229232.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\nFailed to download (trying next):\n<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 28881/28881 [00:00<00:00, 470892.54it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\nFailed to download (trying next):\n<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1648877/1648877 [00:00<00:00, 4377517.71it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\nFailed to download (trying next):\n<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 4542/4542 [00:00<00:00, 2193245.31it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n\nEpoch [1/50] - Loss D: 0.6140, Loss G: 0.4917\nGenerated images saved at epoch 0\nEpoch [2/50] - Loss D: 0.3628, Loss G: 1.2755\nEpoch [3/50] - Loss D: 0.5363, Loss G: 1.4788\nEpoch [4/50] - Loss D: 0.4729, Loss G: 2.2245\nEpoch [5/50] - Loss D: 0.4862, Loss G: 0.6952\nEpoch [6/50] - Loss D: 0.3967, Loss G: 1.1469\nEpoch [7/50] - Loss D: 0.6061, Loss G: 0.6028\nEpoch [8/50] - Loss D: 0.4652, Loss G: 1.3220\nEpoch [9/50] - Loss D: 0.5393, Loss G: 1.7246\nEpoch [10/50] - Loss D: 0.5689, Loss G: 1.1219\nEpoch [11/50] - Loss D: 0.5667, Loss G: 0.7778\nGenerated images saved at epoch 10\nEpoch [12/50] - Loss D: 0.5913, Loss G: 1.4607\nEpoch [13/50] - Loss D: 0.5403, Loss G: 0.7837\nEpoch [14/50] - Loss D: 0.5712, Loss G: 0.9100\nEpoch [15/50] - Loss D: 0.5225, Loss G: 0.8788\nEpoch [16/50] - Loss D: 0.5730, Loss G: 1.0738\nEpoch [17/50] - Loss D: 0.7263, Loss G: 1.5403\nEpoch [18/50] - Loss D: 0.6133, Loss G: 1.1867\nEpoch [19/50] - Loss D: 0.5569, Loss G: 0.9480\nEpoch [20/50] - Loss D: 0.5364, Loss G: 1.1285\nEpoch [21/50] - Loss D: 0.4987, Loss G: 1.0476\nGenerated images saved at epoch 20\nEpoch [22/50] - Loss D: 0.5201, Loss G: 0.9426\nEpoch [23/50] - Loss D: 0.5557, Loss G: 1.2902\nEpoch [24/50] - Loss D: 0.5379, Loss G: 1.1187\nEpoch [25/50] - Loss D: 0.5324, Loss G: 0.8536\nEpoch [26/50] - Loss D: 0.5426, Loss G: 1.1762\nEpoch [27/50] - Loss D: 0.6029, Loss G: 0.6973\nEpoch [28/50] - Loss D: 0.5611, Loss G: 1.2292\nEpoch [29/50] - Loss D: 0.5666, Loss G: 1.2118\nEpoch [30/50] - Loss D: 0.5802, Loss G: 0.6384\nEpoch [31/50] - Loss D: 0.6060, Loss G: 1.2668\nGenerated images saved at epoch 30\nEpoch [32/50] - Loss D: 0.5559, Loss G: 1.4407\nEpoch [33/50] - Loss D: 0.5989, Loss G: 0.9308\nEpoch [34/50] - Loss D: 0.5793, Loss G: 1.1984\nEpoch [35/50] - Loss D: 0.5316, Loss G: 0.9050\nEpoch [36/50] - Loss D: 0.5776, Loss G: 0.6762\nEpoch [37/50] - Loss D: 0.5520, Loss G: 1.0254\nEpoch [38/50] - Loss D: 0.4744, Loss G: 1.1513\nEpoch [39/50] - Loss D: 0.6570, Loss G: 0.6853\nEpoch [40/50] - Loss D: 0.5600, Loss G: 1.1350\nEpoch [41/50] - Loss D: 0.5750, Loss G: 1.2057\nGenerated images saved at epoch 40\nEpoch [42/50] - Loss D: 0.5327, Loss G: 1.2860\nEpoch [43/50] - Loss D: 0.5567, Loss G: 1.4477\nEpoch [44/50] - Loss D: 0.4678, Loss G: 1.1835\nEpoch [45/50] - Loss D: 0.5947, Loss G: 0.7984\nEpoch [46/50] - Loss D: 0.5598, Loss G: 0.7938\nEpoch [47/50] - Loss D: 0.5615, Loss G: 1.3013\nEpoch [48/50] - Loss D: 0.5908, Loss G: 0.7742\nEpoch [49/50] - Loss D: 0.5421, Loss G: 1.0381\nEpoch [50/50] - Loss D: 0.5285, Loss G: 1.2984\nTraining complete.\n","output_type":"stream"}],"execution_count":1}]}